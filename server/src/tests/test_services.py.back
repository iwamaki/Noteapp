# server/src/tests/test_services.py

import pytest
import asyncio
from unittest.mock import patch, MagicMock, AsyncMock

# 親ディレクトリをsys.pathに追加して、servicesやmodelsをインポートできるようにする
import sys
import os

# 相対パスでのインポートではなく、srcディレクトリをPYTHONPATHに追加
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

# そして絶対パスでインポート
from src.services import SimpleLLMService
from src.models import ChatContext

# --- テスト用のダミークラス ---
# langchain.schemaのクラスの代わりに使用
class DummyMessage:
    def __init__(self, content):
        self.content = content
    def __repr__(self):
        return f"{self.__class__.__name__}(content='{self.content}')"

class DummySystemMessage(DummyMessage): pass
class DummyHumanMessage(DummyMessage): pass
class DummyAIMessage(DummyMessage): pass


@pytest.fixture(autouse=True)
def patch_langchain_classes(monkeypatch):
    """
    テスト実行中、servicesモジュール内のLangChainクラスをダミークラスに差し替える
    """
    # langchain.schemaモジュール自体をモックする
    mock_schema = MagicMock()
    mock_schema.HumanMessage = DummyHumanMessage
    mock_schema.SystemMessage = DummySystemMessage
    mock_schema.AIMessage = DummyAIMessage
    
    monkeypatch.setitem(sys.modules, 'langchain.schema', mock_schema)
    monkeypatch.setitem(sys.modules, 'langchain_openai', MagicMock())
    monkeypatch.setitem(sys.modules, 'langchain_google_genai', MagicMock())


@pytest.mark.asyncio
@patch('langchain_openai.ChatOpenAI')
async def test_process_chat_with_history_openai(MockChatOpenAI):
    """
    OpenAIプロバイダーを使用したprocess_chatメソッドで、
    会話履歴が正しくmessagesリストに挿入され、
    履歴のカウントとレスポンスメッセージが正しく返されることを確認するテスト
    """
    # Arrange
    mock_llm_instance = MagicMock()
    mock_llm_instance.invoke = MagicMock(return_value=MagicMock(content="AI Response", tool_calls=None))
    mock_llm_instance.bind_tools.return_value = mock_llm_instance
    MockChatOpenAI.return_value = mock_llm_instance

    service = SimpleLLMService()
    service.openai_api_key = "fake-key"

    history = [
        {'role': 'user', 'content': 'First question'},
        {'role': 'ai', 'content': 'First answer'},
    ]
    context = ChatContext(conversationHistory=history)
    
    # Act
    response = await service.process_chat(
        message="Second question",
        provider="openai",
        context=context
    )

    # Assert
    mock_llm_instance.invoke.assert_called_once()
    called_messages = mock_llm_instance.invoke.call_args[0][0]
    
    assert len(called_messages) == 4  # System, User, AI, User
    assert isinstance(called_messages[0], DummySystemMessage)
    assert isinstance(called_messages[1], DummyHumanMessage)
    assert called_messages[1].content == 'First question'
    assert isinstance(called_messages[2], DummyAIMessage)
    assert called_messages[2].content == 'First answer'
    assert isinstance(called_messages[3], DummyHumanMessage)
    assert called_messages[3].content == 'Second question'
    
    assert response.historyCount == 2
    assert response.message == "AI Response"


@pytest.mark.asyncio
@patch('langchain_google_genai.ChatGoogleGenerativeAI')
async def test_process_chat_with_history_gemini(MockChatGoogleGenerativeAI):
    """
    Geminiプロバイダーを使用したprocess_chatメソッドで、
    会話履歴が正しくmessagesリストに挿入され、
    履歴のカウントとレスポンスメッセージが正しく返されることを確認するテスト
    """
    # Arrange
    mock_llm_instance = MagicMock()
    mock_llm_instance.invoke = MagicMock(return_value=MagicMock(content="AI Response", tool_calls=None))
    mock_llm_instance.bind_tools.return_value = mock_llm_instance
    MockChatGoogleGenerativeAI.return_value = mock_llm_instance

    service = SimpleLLMService()
    service.gemini_api_key = "fake-key"

    history = [
        {'role': 'user', 'content': 'First question'},
        {'role': 'ai', 'content': 'First answer'},
    ]
    context = ChatContext(conversationHistory=history)
    
    # Act
    response = await service.process_chat(
        message="Second question",
        provider="gemini",
        context=context
    )

    # Assert
    mock_llm_instance.invoke.assert_called_once()
    called_messages = mock_llm_instance.invoke.call_args[0][0]
    
    assert len(called_messages) == 4  # System, User, AI, User
    assert isinstance(called_messages[0], DummySystemMessage)
    assert isinstance(called_messages[1], DummyHumanMessage)
    assert called_messages[1].content == 'First question'
    assert isinstance(called_messages[2], DummyAIMessage)
    assert called_messages[2].content == 'First answer'
    assert isinstance(called_messages[3], DummyHumanMessage)
    assert called_messages[3].content == 'Second question'
    
    assert response.historyCount == 2
    assert response.message == "AI Response"
